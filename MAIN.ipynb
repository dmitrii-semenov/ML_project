{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MPA-MLF: Final project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Made by Dmitrii Semenov, Josef Pecka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import general libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import main functions for ML\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Import Tuner\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "from keras_tuner.engine.hyperparameters import HyperParameters\n",
    "\n",
    "# Import confusion matrix fucntion\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Set plot font \n",
    "font = {'weight' : 'bold',\n",
    "        'size'   : 12}\n",
    "\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Load input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loaded 1491 samples of shape (72, 48)\n",
      "[INFO] Max value of X data 76.52984619140625\n",
      "[INFO] Min value of X data -66.49512481689453\n"
     ]
    }
   ],
   "source": [
    "# Set dataset paths\n",
    "dataset_dir = \"\"\n",
    "train_dir = os.path.join(dataset_dir, \"Train\")\n",
    "test_dir = os.path.join(dataset_dir, \"Test\")\n",
    "labels_path = os.path.join(dataset_dir, \"label_train.csv\")\n",
    "test_format_path = os.path.join(dataset_dir, \"test_format.csv\")\n",
    "\n",
    "# Load labels file\n",
    "labels_df = pd.read_csv(labels_path)\n",
    "\n",
    "# Prepare containers\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# Loop through each file ID\n",
    "for _, row in labels_df.iterrows():\n",
    "    file_name = f\"{row['ID']}.npy\"\n",
    "    file_path = os.path.join(train_dir, file_name)\n",
    "    try:\n",
    "        sample = np.load(file_path)\n",
    "        X.append(sample)\n",
    "        y.append(row['target'])\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] Could not load {file_name}: {e}\")\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "X = np.array(X, dtype=np.float32)\n",
    "y = np.array(y, dtype=np.int32)\n",
    "\n",
    "print(f\"[INFO] Loaded {X.shape[0]} samples of shape {X.shape[1:]}\")\n",
    "print(f\"[INFO] Max value of X data {np.max(X)}\")\n",
    "print(f\"[INFO] Min value of X data {np.min(X)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Mean value of data after Z-score normalizations: -4.2031363278738354e-08\n",
      "X_train shape: (1192, 72, 48, 1), X_val shape: (299, 72, 48, 1)\n",
      "y_train shape: (1192, 3), y_val shape: (299, 3)\n"
     ]
    }
   ],
   "source": [
    "# Z-score normalization\n",
    "X = X.astype(\"float32\")\n",
    "X_mean = X.mean()\n",
    "X_std = X.std()\n",
    "X = (X - X_mean) / X_std\n",
    "\n",
    "print(f\"[INFO] Mean value of data after Z-score normalizations: {np.mean(X)}\")\n",
    "\n",
    "# Reshape for CNN input\n",
    "X = X.reshape((-1, 72, 48, 1))\n",
    "\n",
    "# One-hot encode labels\n",
    "NUM_CLASSES = 3\n",
    "y = to_categorical(y, NUM_CLASSES)\n",
    "\n",
    "# Train-validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y,\n",
    "    test_size=0.2,\n",
    "    stratify=y.argmax(axis=1),\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Print result\n",
    "print(f\"X_train shape: {X_train.shape}, X_val shape: {X_val.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}, y_val shape: {y_val.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
